{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecf8788f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src='img/cdy.png' style='width:500px; float: left; margin: 0px 30px 15px 0px'></center>\n",
    "\n",
    "# Clustering models\n",
    "## Class 25 - Data Science Curriculum \n",
    "\n",
    "<br>\n",
    "\n",
    "#### Women Building Change scholarship program 2023 üáßüáÆ\n",
    "May 31, 2023\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d145e2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ‚è™ Recap last class\n",
    "\n",
    "- Classification models\n",
    "    - Logistic regression \n",
    "    - Naive Bayes\n",
    "    - Support Vector Machines (SVM)\n",
    "    - Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59660346",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# üöÄ Today's agenda\n",
    "\n",
    "- Clustering models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23fbace",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Classification models in the context of machine learning\n",
    "<br>\n",
    "<center><img src='img/clase7/clas2.png' style='height:450px; float: center; margin: 0px 0px 0px 0px'></center>\n",
    "\n",
    "- Classification models are **SUPERVISED LEARNING** with **discrete** labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd5836f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ü§î What if we don't have labels?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f86369c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src='img/clustering.png' style='height:600px; float: center; margin: 0px 0px 0px 0px'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae89f56e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ü§ñ Clustering algorithms\n",
    "\n",
    "It's the most popular way to do unsupervised learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8dd17f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Data\n",
    "\n",
    "‚Ä¢ We have training observations $\\{ x_1, \\ldots, x_n\\} \\in \\mathbb{R}^{n}$\n",
    "\n",
    "‚Ä¢ We don't need <i>(have)</i> labels $y_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a964a49",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## First (?) clustering application\n",
    "\n",
    "‚Ä¢ In the 1850s, John Snow, a doctor in London, plotted the location of the deaths by cholera in a map\n",
    "\n",
    "\n",
    "‚Ä¢ The locations showed that the cases were clustered in the road intersections where there were contaminated wells \n",
    "\n",
    "<br>\n",
    "<center><img src='img/clase9/img3b.png' style='height:300px'><small>Source: Nina Mishra HP Labs</small></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00b9444",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ü§ñ Clustering algorithms\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f1a84c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<b> Objective:</b> Group similar observations together-- \"clusters\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84d7f74",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<b> When do we use them?</b> When we don't know what we are looking for"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba58e383",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<b>... but be careful! It can quickly become garbage</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3abccd",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "```python\n",
    "The dataset should have:\n",
    "    - High intra-class similarity\n",
    "    - Low inter-class similarity\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65292e95",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ü§ñ Clustering algorithms\n",
    "<br>\n",
    "\n",
    "The most popular model is **K-MEANS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061805f9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# K-means\n",
    "\n",
    "<center><img src='img/clase9/img7bc.gif' style='height:150px'></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2487ba",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>K-means an <b><u>iterative</u></b> algorithm whose objective is to partition a set of $N$ observations into $K$ groups in which each observation belongs to the group whose mean value is closest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bf9923",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### K-means --- Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d4590a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src='img/km1.png' style='height:250px; float: left; margin: 0px 50px 0px 0px'>\n",
    "\n",
    "<b> 1. Initialize</b>\n",
    "<br><br>A. &nbsp; Choose a number $K$ of clusters\n",
    "<br><br>B. &nbsp; Randomly choose $K$ points as centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a700144f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src='img/km2.png' style='height:250px; float: right; margin: 0px 0px 0px 0px'>\n",
    "\n",
    "\n",
    "<img src='img/km3.png' style='height:250px; float: right; margin: 0px 0px 0px 0px'></center>\n",
    "\n",
    "<b>2. Repeat</b>\n",
    "<br><br>A. &nbsp; The $K$ clusters are created by assigning to each observation to its closest centroid\n",
    "<br><br>B. &nbsp; The new centroid of each one of the $K$ clusters is the mean of their observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f36736c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='img/km4.png' style='height:250px; float: left; margin: 0px 50px 0px 0px'>\n",
    "\n",
    "<b>3. Stop </b>\n",
    "<br><br>A. &nbsp; Repeat step 1 and 2\n",
    "<br><br>B. &nbsp; The algorithm ends when one of the following happens:\n",
    "        - There's no change in the centroids\n",
    "        - The observations continue to be assigned to the same cluster\n",
    "        - The maximum number of iterations is reached"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8ce8f0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### References:\n",
    "    \n",
    "- The math behind it: [Link](https://nlp.stanford.edu/IR-book/html/htmledition/k-means-1.html)\n",
    "\n",
    "- Visualize: [Video](https://www.youtube.com/watch?v=BVFG7fd1H30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cea9392",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### üëÆ‚Äç‚ôÄÔ∏è Check point!\n",
    "<br>\n",
    "<img src='img/clase9/kmeans2.png' style='height:700px; float: right; margin: 0px 50px 0px 0px'>\n",
    "\n",
    "- What's $K$ in this example?\n",
    "\n",
    "- Tell me what is happening on each step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5a3469",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# üë©‚Äçüíª Let's code!\n",
    "<b>Step 1:</b> Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e8b82b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5853aaa5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<b>Step 2:</b> Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9752b0b5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def pre_process(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[\\W\\d]+\", \" \", text)\n",
    "    return text\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(preprocessor=pre_process)\n",
    "tfidf = tfidf_vect.fit_transform(data.Text.values)\n",
    "tfidf_matrix = pd.DataFrame(tfidf.toarray(), columns = tfidf_vect.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42034526",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<b>Step 3:</b> Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af09298",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "But first we have to pick $K$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d317e4bf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How do we pick the best $K$?\n",
    "\n",
    "<br>\n",
    "<center><img src='img/clase9/pickk1.png' style='height:600px'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c638227",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How do we pick the best $K$?\n",
    "\n",
    "\n",
    "#### How many clusters are there here?\n",
    "\n",
    "<br>\n",
    "<center><img src='img/cc1.png'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b953f5a4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How do we pick the best $K$?\n",
    "\n",
    "\n",
    "#### How many clusters are there here?\n",
    "\n",
    "#### Two?\n",
    "\n",
    "<br>\n",
    "<center><img src='img/cc2.png'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044adda2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How do we pick the best $K$?\n",
    "\n",
    "\n",
    "#### How many clusters are there here?\n",
    "\n",
    "#### Eight?\n",
    "\n",
    "<br>\n",
    "<center><img src='img/cc3.png'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30af65ba",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### üëÆ‚Äç‚ôÄÔ∏è Check point\n",
    "<br>\n",
    "\n",
    "‚Ä¢ What is the minimum possible value for $K$?\n",
    "\n",
    "‚Ä¢ What is the maximum possible value for $K$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103dc1bb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<b>Step 3:</b> Train the model\n",
    "\n",
    "**Pick $K$ using the elbow method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d69e2e6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104cb28d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "ks = []\n",
    "k_inertias = []\n",
    "\n",
    "for k in range(1,10):\n",
    "    kmeans = KMeans(n_clusters=k).fit(tfidf_matrix)\n",
    "    k_inertia = kmeans.inertia_\n",
    "    \n",
    "    ks.append(k)\n",
    "    k_inertias.append(k_inertia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77624ed",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# list(zip(ks,k_inertias))\n",
    "\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"Inertia\")\n",
    "plt.title(\"Elbow method\")\n",
    "plt.plot(ks, k_inertias, 'bx-');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffb548b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "k = 4\n",
    "model = KMeans(n_clusters=k)\n",
    "model.fit(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37d7fdf",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data['cluster'] = model.labels_\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d29284",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class color:\n",
    "    PURPLE = '\\033[95m'\n",
    "    CYAN = '\\033[96m'\n",
    "    DARKCYAN = '\\033[36m'\n",
    "    BLUE = '\\033[94m'\n",
    "    GREEN = '\\033[92m'\n",
    "    YELLOW = '\\033[93m'\n",
    "    RED = '\\033[91m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cde187d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "k_pt = 4\n",
    "model = KMeans(n_clusters=k_pt)\n",
    "model.fit(tfidf_matrix)\n",
    "nbrs = NearestNeighbors(n_neighbors=3, metric='euclidean').fit(tfidf_matrix.values)\n",
    "\n",
    "data['cluster'] = model.labels_\n",
    "clust_cnt = data['cluster'].value_counts()\n",
    "clust_cnt_pct = data['cluster'].value_counts(normalize=True)\n",
    "\n",
    "print(f\"{color.BOLD}CLUSTERS:\\n{color.END}\")\n",
    "centroids = model.cluster_centers_\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = tfidf_vect.get_feature_names()\n",
    "\n",
    "for i in range(k_pt):\n",
    "    print(f\"{color.BLUE}Cluster {i}:{color.END}\")\n",
    "    print(f\"{color.CYAN}COUNT {color.END} {clust_cnt[i]} comments ({clust_cnt_pct[i]:.2%} of the data)\")\n",
    "    print(f\"{color.CYAN}TERMS {color.END}\", end=\" \")\n",
    "    for ind in order_centroids[i, :20]:\n",
    "        print(f'{color.BOLD}{terms[ind]}{color.END}', end=\" \"),\n",
    "    print(f\"\\n{color.CYAN}REPRESENTATIVE COMMENTS{color.END}\")\n",
    "    for comment in data.iloc[nbrs.kneighbors([centroids[i]])[1][0]]['Text'].values:\n",
    "        print(f\"* {comment}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b88cf3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "clusters = {0:'Russian',\n",
    "            1:'French',\n",
    "            2:'Spanish',\n",
    "            3:'Portuguese'}\n",
    "\n",
    "data['cluster'] = data['cluster'].apply(lambda val: clusters[val])\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc90a85c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df_centroides = pd.DataFrame(model.cluster_centers_)\n",
    "df_centroides['cluster'] = clusters.values()\n",
    "df_centroides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a2ca69",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bda899",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "\n",
    "result = pca.fit_transform(tfidf_matrix)\n",
    "result = pd.DataFrame(result)\n",
    "result.columns = ['X', 'Y']\n",
    "result['cluster'] = data.cluster.values\n",
    "result['texto'] = data.Text.apply(lambda val: val[:140])\n",
    "\n",
    "colorsIdx = {'Russian': 'blue', \n",
    "             'Spanish': 'yellow',\n",
    "             'Portuguese': 'green',\n",
    "             'French': 'red'}\n",
    "\n",
    "cols = data['cluster'].map(colorsIdx)\n",
    "\n",
    "trace = go.Scatter(x=result['X'].values,\n",
    "                   y=result['Y'].values,\n",
    "                   text=result['texto'].values,\n",
    "                   mode='markers',\n",
    "                   marker=dict(color=cols)) \n",
    "\n",
    "layout = go.Layout(title=\"PCA\")\n",
    "\n",
    "fig = go.Figure(data=trace, layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce64af05",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<b>Step 4:</b> Make predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe7de2f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d8c332c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src='img/bye.gif' style='height:250px;'></center> \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
